{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VjZ6bKX2EZ8",
        "outputId": "f8c92ca2-3cb4-438e-8a19-b21a3261e316"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nIYmEMt2fpS",
        "outputId": "b67f0a05-0063-4c3c-efec-ede260e1a3b5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'Colab Notebooks'\n",
            " dataset.zip\n",
            "'Google AI Studio'\n",
            " IMG-20250612-WA0000.jpg\n",
            " IMG-20251008-WA0008.jpg\n",
            "'Machine Learning Training - Certificate of Completion (1).pdf'\n",
            " PHOTO_1_11zon.jpg\n",
            "'RB LEVEL 1 C.pdf'\n",
            "'RB LEVEL 2 C.pdf'\n",
            "'Ruturaj Bhujbal(Core).pdf'\n",
            " VID_20250414_141757.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/drive/MyDrive/dataset.zip\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7K_ggJAg2jIt",
        "outputId": "bf474751-6452-4746-d702-78dbd8faa25d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/dataset.zip\n",
            "   creating: dataset/\n",
            "   creating: dataset/Center/\n",
            "  inflating: dataset/Center/0.png    \n",
            "  inflating: dataset/Center/1.png    \n",
            "  inflating: dataset/Center/10.png   \n",
            "  inflating: dataset/Center/100.png  \n",
            "  inflating: dataset/Center/101.png  \n",
            "  inflating: dataset/Center/102.png  \n",
            "  inflating: dataset/Center/103.png  \n",
            "  inflating: dataset/Center/104.png  \n",
            "  inflating: dataset/Center/105.png  \n",
            "  inflating: dataset/Center/106.png  \n",
            "  inflating: dataset/Center/107.png  \n",
            "  inflating: dataset/Center/108.png  \n",
            "  inflating: dataset/Center/109.png  \n",
            "  inflating: dataset/Center/11.png   \n",
            "  inflating: dataset/Center/110.png  \n",
            "  inflating: dataset/Center/111.png  \n",
            "  inflating: dataset/Center/112.png  \n",
            "  inflating: dataset/Center/113.png  \n",
            "  inflating: dataset/Center/114.png  \n",
            "  inflating: dataset/Center/115.png  \n",
            "  inflating: dataset/Center/116.png  \n",
            "  inflating: dataset/Center/117.png  \n",
            "  inflating: dataset/Center/118.png  \n",
            "  inflating: dataset/Center/119.png  \n",
            "  inflating: dataset/Center/12.png   \n",
            "  inflating: dataset/Center/13.png   \n",
            "  inflating: dataset/Center/14.png   \n",
            "  inflating: dataset/Center/15.png   \n",
            "  inflating: dataset/Center/16.png   \n",
            "  inflating: dataset/Center/17.png   \n",
            "  inflating: dataset/Center/18.png   \n",
            "  inflating: dataset/Center/19.png   \n",
            "  inflating: dataset/Center/2.png    \n",
            "  inflating: dataset/Center/20.png   \n",
            "  inflating: dataset/Center/21.png   \n",
            "  inflating: dataset/Center/22.png   \n",
            "  inflating: dataset/Center/23.png   \n",
            "  inflating: dataset/Center/24.png   \n",
            "  inflating: dataset/Center/25.png   \n",
            "  inflating: dataset/Center/26.png   \n",
            "  inflating: dataset/Center/27.png   \n",
            "  inflating: dataset/Center/28.png   \n",
            "  inflating: dataset/Center/29.png   \n",
            "  inflating: dataset/Center/3.png    \n",
            "  inflating: dataset/Center/30.png   \n",
            "  inflating: dataset/Center/31.png   \n",
            "  inflating: dataset/Center/32.png   \n",
            "  inflating: dataset/Center/33.png   \n",
            "  inflating: dataset/Center/34.png   \n",
            "  inflating: dataset/Center/35.png   \n",
            "  inflating: dataset/Center/36.png   \n",
            "  inflating: dataset/Center/37.png   \n",
            "  inflating: dataset/Center/38.png   \n",
            "  inflating: dataset/Center/39.png   \n",
            "  inflating: dataset/Center/4.png    \n",
            "  inflating: dataset/Center/40.png   \n",
            "  inflating: dataset/Center/41.png   \n",
            "  inflating: dataset/Center/42.png   \n",
            "  inflating: dataset/Center/43.png   \n",
            "  inflating: dataset/Center/44.png   \n",
            "  inflating: dataset/Center/45.png   \n",
            "  inflating: dataset/Center/46.png   \n",
            "  inflating: dataset/Center/47.png   \n",
            "  inflating: dataset/Center/48.png   \n",
            "  inflating: dataset/Center/49.png   \n",
            "  inflating: dataset/Center/5.png    \n",
            "  inflating: dataset/Center/50.png   \n",
            "  inflating: dataset/Center/51.png   \n",
            "  inflating: dataset/Center/52.png   \n",
            "  inflating: dataset/Center/53.png   \n",
            "  inflating: dataset/Center/54.png   \n",
            "  inflating: dataset/Center/55.png   \n",
            "  inflating: dataset/Center/56.png   \n",
            "  inflating: dataset/Center/57.png   \n",
            "  inflating: dataset/Center/58.png   \n",
            "  inflating: dataset/Center/59.png   \n",
            "  inflating: dataset/Center/6.png    \n",
            "  inflating: dataset/Center/60.png   \n",
            "  inflating: dataset/Center/61.png   \n",
            "  inflating: dataset/Center/62.png   \n",
            "  inflating: dataset/Center/63.png   \n",
            "  inflating: dataset/Center/64.png   \n",
            "  inflating: dataset/Center/65.png   \n",
            "  inflating: dataset/Center/66.png   \n",
            "  inflating: dataset/Center/67.png   \n",
            "  inflating: dataset/Center/68.png   \n",
            "  inflating: dataset/Center/69.png   \n",
            "  inflating: dataset/Center/7.png    \n",
            "  inflating: dataset/Center/70.png   \n",
            "  inflating: dataset/Center/71.png   \n",
            "  inflating: dataset/Center/72.png   \n",
            "  inflating: dataset/Center/73.png   \n",
            "  inflating: dataset/Center/74.png   \n",
            "  inflating: dataset/Center/75.png   \n",
            "  inflating: dataset/Center/76.png   \n",
            "  inflating: dataset/Center/77.png   \n",
            "  inflating: dataset/Center/78.png   \n",
            "  inflating: dataset/Center/79.png   \n",
            "  inflating: dataset/Center/8.png    \n",
            "  inflating: dataset/Center/80.png   \n",
            "  inflating: dataset/Center/81.png   \n",
            "  inflating: dataset/Center/82.png   \n",
            "  inflating: dataset/Center/83.png   \n",
            "  inflating: dataset/Center/84.png   \n",
            "  inflating: dataset/Center/85.png   \n",
            "  inflating: dataset/Center/86.png   \n",
            "  inflating: dataset/Center/87.png   \n",
            "  inflating: dataset/Center/88.png   \n",
            "  inflating: dataset/Center/89.png   \n",
            "  inflating: dataset/Center/9.png    \n",
            "  inflating: dataset/Center/90.png   \n",
            "  inflating: dataset/Center/91.png   \n",
            "  inflating: dataset/Center/92.png   \n",
            "  inflating: dataset/Center/93.png   \n",
            "  inflating: dataset/Center/94.png   \n",
            "  inflating: dataset/Center/95.png   \n",
            "  inflating: dataset/Center/96.png   \n",
            "  inflating: dataset/Center/97.png   \n",
            "  inflating: dataset/Center/98.png   \n",
            "  inflating: dataset/Center/99.png   \n",
            "   creating: dataset/Donut/\n",
            "  inflating: dataset/Donut/0.png     \n",
            "  inflating: dataset/Donut/1.png     \n",
            "  inflating: dataset/Donut/10.png    \n",
            "  inflating: dataset/Donut/100.png   \n",
            "  inflating: dataset/Donut/101.png   \n",
            "  inflating: dataset/Donut/102.png   \n",
            "  inflating: dataset/Donut/103.png   \n",
            "  inflating: dataset/Donut/104.png   \n",
            "  inflating: dataset/Donut/105.png   \n",
            "  inflating: dataset/Donut/106.png   \n",
            "  inflating: dataset/Donut/107.png   \n",
            "  inflating: dataset/Donut/108.png   \n",
            "  inflating: dataset/Donut/109.png   \n",
            "  inflating: dataset/Donut/11.png    \n",
            "  inflating: dataset/Donut/110.png   \n",
            "  inflating: dataset/Donut/111.png   \n",
            "  inflating: dataset/Donut/112.png   \n",
            "  inflating: dataset/Donut/113.png   \n",
            "  inflating: dataset/Donut/114.png   \n",
            "  inflating: dataset/Donut/115.png   \n",
            "  inflating: dataset/Donut/116.png   \n",
            "  inflating: dataset/Donut/117.png   \n",
            "  inflating: dataset/Donut/118.png   \n",
            "  inflating: dataset/Donut/119.png   \n",
            "  inflating: dataset/Donut/12.png    \n",
            "  inflating: dataset/Donut/13.png    \n",
            "  inflating: dataset/Donut/14.png    \n",
            "  inflating: dataset/Donut/15.png    \n",
            "  inflating: dataset/Donut/16.png    \n",
            "  inflating: dataset/Donut/17.png    \n",
            "  inflating: dataset/Donut/18.png    \n",
            "  inflating: dataset/Donut/19.png    \n",
            "  inflating: dataset/Donut/2.png     \n",
            "  inflating: dataset/Donut/20.png    \n",
            "  inflating: dataset/Donut/21.png    \n",
            "  inflating: dataset/Donut/22.png    \n",
            "  inflating: dataset/Donut/23.png    \n",
            "  inflating: dataset/Donut/24.png    \n",
            "  inflating: dataset/Donut/25.png    \n",
            "  inflating: dataset/Donut/26.png    \n",
            "  inflating: dataset/Donut/27.png    \n",
            "  inflating: dataset/Donut/28.png    \n",
            "  inflating: dataset/Donut/29.png    \n",
            "  inflating: dataset/Donut/3.png     \n",
            "  inflating: dataset/Donut/30.png    \n",
            "  inflating: dataset/Donut/31.png    \n",
            "  inflating: dataset/Donut/32.png    \n",
            "  inflating: dataset/Donut/33.png    \n",
            "  inflating: dataset/Donut/34.png    \n",
            "  inflating: dataset/Donut/35.png    \n",
            "  inflating: dataset/Donut/36.png    \n",
            "  inflating: dataset/Donut/37.png    \n",
            "  inflating: dataset/Donut/38.png    \n",
            "  inflating: dataset/Donut/39.png    \n",
            "  inflating: dataset/Donut/4.png     \n",
            "  inflating: dataset/Donut/40.png    \n",
            "  inflating: dataset/Donut/41.png    \n",
            "  inflating: dataset/Donut/42.png    \n",
            "  inflating: dataset/Donut/43.png    \n",
            "  inflating: dataset/Donut/44.png    \n",
            "  inflating: dataset/Donut/45.png    \n",
            "  inflating: dataset/Donut/46.png    \n",
            "  inflating: dataset/Donut/47.png    \n",
            "  inflating: dataset/Donut/48.png    \n",
            "  inflating: dataset/Donut/49.png    \n",
            "  inflating: dataset/Donut/5.png     \n",
            "  inflating: dataset/Donut/50.png    \n",
            "  inflating: dataset/Donut/51.png    \n",
            "  inflating: dataset/Donut/52.png    \n",
            "  inflating: dataset/Donut/53.png    \n",
            "  inflating: dataset/Donut/54.png    \n",
            "  inflating: dataset/Donut/55.png    \n",
            "  inflating: dataset/Donut/56.png    \n",
            "  inflating: dataset/Donut/57.png    \n",
            "  inflating: dataset/Donut/58.png    \n",
            "  inflating: dataset/Donut/59.png    \n",
            "  inflating: dataset/Donut/6.png     \n",
            "  inflating: dataset/Donut/60.png    \n",
            "  inflating: dataset/Donut/61.png    \n",
            "  inflating: dataset/Donut/62.png    \n",
            "  inflating: dataset/Donut/63.png    \n",
            "  inflating: dataset/Donut/64.png    \n",
            "  inflating: dataset/Donut/65.png    \n",
            "  inflating: dataset/Donut/66.png    \n",
            "  inflating: dataset/Donut/67.png    \n",
            "  inflating: dataset/Donut/68.png    \n",
            "  inflating: dataset/Donut/69.png    \n",
            "  inflating: dataset/Donut/7.png     \n",
            "  inflating: dataset/Donut/70.png    \n",
            "  inflating: dataset/Donut/71.png    \n",
            "  inflating: dataset/Donut/72.png    \n",
            "  inflating: dataset/Donut/73.png    \n",
            "  inflating: dataset/Donut/74.png    \n",
            "  inflating: dataset/Donut/75.png    \n",
            "  inflating: dataset/Donut/76.png    \n",
            "  inflating: dataset/Donut/77.png    \n",
            "  inflating: dataset/Donut/78.png    \n",
            "  inflating: dataset/Donut/79.png    \n",
            "  inflating: dataset/Donut/8.png     \n",
            "  inflating: dataset/Donut/80.png    \n",
            "  inflating: dataset/Donut/81.png    \n",
            "  inflating: dataset/Donut/82.png    \n",
            "  inflating: dataset/Donut/83.png    \n",
            "  inflating: dataset/Donut/84.png    \n",
            "  inflating: dataset/Donut/85.png    \n",
            "  inflating: dataset/Donut/86.png    \n",
            "  inflating: dataset/Donut/87.png    \n",
            "  inflating: dataset/Donut/88.png    \n",
            "  inflating: dataset/Donut/89.png    \n",
            "  inflating: dataset/Donut/9.png     \n",
            "  inflating: dataset/Donut/90.png    \n",
            "  inflating: dataset/Donut/91.png    \n",
            "  inflating: dataset/Donut/92.png    \n",
            "  inflating: dataset/Donut/93.png    \n",
            "  inflating: dataset/Donut/94.png    \n",
            "  inflating: dataset/Donut/95.png    \n",
            "  inflating: dataset/Donut/96.png    \n",
            "  inflating: dataset/Donut/97.png    \n",
            "  inflating: dataset/Donut/98.png    \n",
            "  inflating: dataset/Donut/99.png    \n",
            "   creating: dataset/Edge-Loc/\n",
            "  inflating: dataset/Edge-Loc/0.png  \n",
            "  inflating: dataset/Edge-Loc/1.png  \n",
            "  inflating: dataset/Edge-Loc/10.png  \n",
            "  inflating: dataset/Edge-Loc/100.png  \n",
            "  inflating: dataset/Edge-Loc/101.png  \n",
            "  inflating: dataset/Edge-Loc/102.png  \n",
            "  inflating: dataset/Edge-Loc/103.png  \n",
            "  inflating: dataset/Edge-Loc/104.png  \n",
            "  inflating: dataset/Edge-Loc/105.png  \n",
            "  inflating: dataset/Edge-Loc/106.png  \n",
            "  inflating: dataset/Edge-Loc/107.png  \n",
            "  inflating: dataset/Edge-Loc/108.png  \n",
            "  inflating: dataset/Edge-Loc/109.png  \n",
            "  inflating: dataset/Edge-Loc/11.png  \n",
            "  inflating: dataset/Edge-Loc/110.png  \n",
            "  inflating: dataset/Edge-Loc/111.png  \n",
            "  inflating: dataset/Edge-Loc/112.png  \n",
            "  inflating: dataset/Edge-Loc/113.png  \n",
            "  inflating: dataset/Edge-Loc/114.png  \n",
            "  inflating: dataset/Edge-Loc/115.png  \n",
            "  inflating: dataset/Edge-Loc/116.png  \n",
            "  inflating: dataset/Edge-Loc/117.png  \n",
            "  inflating: dataset/Edge-Loc/118.png  \n",
            "  inflating: dataset/Edge-Loc/119.png  \n",
            "  inflating: dataset/Edge-Loc/12.png  \n",
            "  inflating: dataset/Edge-Loc/13.png  \n",
            "  inflating: dataset/Edge-Loc/14.png  \n",
            "  inflating: dataset/Edge-Loc/15.png  \n",
            "  inflating: dataset/Edge-Loc/16.png  \n",
            "  inflating: dataset/Edge-Loc/17.png  \n",
            "  inflating: dataset/Edge-Loc/18.png  \n",
            "  inflating: dataset/Edge-Loc/19.png  \n",
            "  inflating: dataset/Edge-Loc/2.png  \n",
            "  inflating: dataset/Edge-Loc/20.png  \n",
            "  inflating: dataset/Edge-Loc/21.png  \n",
            "  inflating: dataset/Edge-Loc/22.png  \n",
            "  inflating: dataset/Edge-Loc/23.png  \n",
            "  inflating: dataset/Edge-Loc/24.png  \n",
            "  inflating: dataset/Edge-Loc/25.png  \n",
            "  inflating: dataset/Edge-Loc/26.png  \n",
            "  inflating: dataset/Edge-Loc/27.png  \n",
            "  inflating: dataset/Edge-Loc/28.png  \n",
            "  inflating: dataset/Edge-Loc/29.png  \n",
            "  inflating: dataset/Edge-Loc/3.png  \n",
            "  inflating: dataset/Edge-Loc/30.png  \n",
            "  inflating: dataset/Edge-Loc/31.png  \n",
            "  inflating: dataset/Edge-Loc/32.png  \n",
            "  inflating: dataset/Edge-Loc/33.png  \n",
            "  inflating: dataset/Edge-Loc/34.png  \n",
            "  inflating: dataset/Edge-Loc/35.png  \n",
            "  inflating: dataset/Edge-Loc/36.png  \n",
            "  inflating: dataset/Edge-Loc/37.png  \n",
            "  inflating: dataset/Edge-Loc/38.png  \n",
            "  inflating: dataset/Edge-Loc/39.png  \n",
            "  inflating: dataset/Edge-Loc/4.png  \n",
            "  inflating: dataset/Edge-Loc/40.png  \n",
            "  inflating: dataset/Edge-Loc/41.png  \n",
            "  inflating: dataset/Edge-Loc/42.png  \n",
            "  inflating: dataset/Edge-Loc/43.png  \n",
            "  inflating: dataset/Edge-Loc/44.png  \n",
            "  inflating: dataset/Edge-Loc/45.png  \n",
            "  inflating: dataset/Edge-Loc/46.png  \n",
            "  inflating: dataset/Edge-Loc/47.png  \n",
            "  inflating: dataset/Edge-Loc/48.png  \n",
            "  inflating: dataset/Edge-Loc/49.png  \n",
            "  inflating: dataset/Edge-Loc/5.png  \n",
            "  inflating: dataset/Edge-Loc/50.png  \n",
            "  inflating: dataset/Edge-Loc/51.png  \n",
            "  inflating: dataset/Edge-Loc/52.png  \n",
            "  inflating: dataset/Edge-Loc/53.png  \n",
            "  inflating: dataset/Edge-Loc/54.png  \n",
            "  inflating: dataset/Edge-Loc/55.png  \n",
            "  inflating: dataset/Edge-Loc/56.png  \n",
            "  inflating: dataset/Edge-Loc/57.png  \n",
            "  inflating: dataset/Edge-Loc/58.png  \n",
            "  inflating: dataset/Edge-Loc/59.png  \n",
            "  inflating: dataset/Edge-Loc/6.png  \n",
            "  inflating: dataset/Edge-Loc/60.png  \n",
            "  inflating: dataset/Edge-Loc/61.png  \n",
            "  inflating: dataset/Edge-Loc/62.png  \n",
            "  inflating: dataset/Edge-Loc/63.png  \n",
            "  inflating: dataset/Edge-Loc/64.png  \n",
            "  inflating: dataset/Edge-Loc/65.png  \n",
            "  inflating: dataset/Edge-Loc/66.png  \n",
            "  inflating: dataset/Edge-Loc/67.png  \n",
            "  inflating: dataset/Edge-Loc/68.png  \n",
            "  inflating: dataset/Edge-Loc/69.png  \n",
            "  inflating: dataset/Edge-Loc/7.png  \n",
            "  inflating: dataset/Edge-Loc/70.png  \n",
            "  inflating: dataset/Edge-Loc/71.png  \n",
            "  inflating: dataset/Edge-Loc/72.png  \n",
            "  inflating: dataset/Edge-Loc/73.png  \n",
            "  inflating: dataset/Edge-Loc/74.png  \n",
            "  inflating: dataset/Edge-Loc/75.png  \n",
            "  inflating: dataset/Edge-Loc/76.png  \n",
            "  inflating: dataset/Edge-Loc/77.png  \n",
            "  inflating: dataset/Edge-Loc/78.png  \n",
            "  inflating: dataset/Edge-Loc/79.png  \n",
            "  inflating: dataset/Edge-Loc/8.png  \n",
            "  inflating: dataset/Edge-Loc/80.png  \n",
            "  inflating: dataset/Edge-Loc/81.png  \n",
            "  inflating: dataset/Edge-Loc/82.png  \n",
            "  inflating: dataset/Edge-Loc/83.png  \n",
            "  inflating: dataset/Edge-Loc/84.png  \n",
            "  inflating: dataset/Edge-Loc/85.png  \n",
            "  inflating: dataset/Edge-Loc/86.png  \n",
            "  inflating: dataset/Edge-Loc/87.png  \n",
            "  inflating: dataset/Edge-Loc/88.png  \n",
            "  inflating: dataset/Edge-Loc/89.png  \n",
            "  inflating: dataset/Edge-Loc/9.png  \n",
            "  inflating: dataset/Edge-Loc/90.png  \n",
            "  inflating: dataset/Edge-Loc/91.png  \n",
            "  inflating: dataset/Edge-Loc/92.png  \n",
            "  inflating: dataset/Edge-Loc/93.png  \n",
            "  inflating: dataset/Edge-Loc/94.png  \n",
            "  inflating: dataset/Edge-Loc/95.png  \n",
            "  inflating: dataset/Edge-Loc/96.png  \n",
            "  inflating: dataset/Edge-Loc/97.png  \n",
            "  inflating: dataset/Edge-Loc/98.png  \n",
            "  inflating: dataset/Edge-Loc/99.png  \n",
            "   creating: dataset/Edge-Ring/\n",
            "  inflating: dataset/Edge-Ring/0.png  \n",
            "  inflating: dataset/Edge-Ring/1.png  \n",
            "  inflating: dataset/Edge-Ring/10.png  \n",
            "  inflating: dataset/Edge-Ring/100.png  \n",
            "  inflating: dataset/Edge-Ring/101.png  \n",
            "  inflating: dataset/Edge-Ring/102.png  \n",
            "  inflating: dataset/Edge-Ring/103.png  \n",
            "  inflating: dataset/Edge-Ring/104.png  \n",
            "  inflating: dataset/Edge-Ring/105.png  \n",
            "  inflating: dataset/Edge-Ring/106.png  \n",
            "  inflating: dataset/Edge-Ring/107.png  \n",
            "  inflating: dataset/Edge-Ring/108.png  \n",
            "  inflating: dataset/Edge-Ring/109.png  \n",
            "  inflating: dataset/Edge-Ring/11.png  \n",
            "  inflating: dataset/Edge-Ring/110.png  \n",
            "  inflating: dataset/Edge-Ring/111.png  \n",
            "  inflating: dataset/Edge-Ring/112.png  \n",
            "  inflating: dataset/Edge-Ring/113.png  \n",
            "  inflating: dataset/Edge-Ring/114.png  \n",
            "  inflating: dataset/Edge-Ring/115.png  \n",
            "  inflating: dataset/Edge-Ring/116.png  \n",
            "  inflating: dataset/Edge-Ring/117.png  \n",
            "  inflating: dataset/Edge-Ring/118.png  \n",
            "  inflating: dataset/Edge-Ring/119.png  \n",
            "  inflating: dataset/Edge-Ring/12.png  \n",
            "  inflating: dataset/Edge-Ring/13.png  \n",
            "  inflating: dataset/Edge-Ring/14.png  \n",
            "  inflating: dataset/Edge-Ring/15.png  \n",
            "  inflating: dataset/Edge-Ring/16.png  \n",
            "  inflating: dataset/Edge-Ring/17.png  \n",
            "  inflating: dataset/Edge-Ring/18.png  \n",
            "  inflating: dataset/Edge-Ring/19.png  \n",
            "  inflating: dataset/Edge-Ring/2.png  \n",
            "  inflating: dataset/Edge-Ring/20.png  \n",
            "  inflating: dataset/Edge-Ring/21.png  \n",
            "  inflating: dataset/Edge-Ring/22.png  \n",
            "  inflating: dataset/Edge-Ring/23.png  \n",
            "  inflating: dataset/Edge-Ring/24.png  \n",
            "  inflating: dataset/Edge-Ring/25.png  \n",
            "  inflating: dataset/Edge-Ring/26.png  \n",
            "  inflating: dataset/Edge-Ring/27.png  \n",
            "  inflating: dataset/Edge-Ring/28.png  \n",
            "  inflating: dataset/Edge-Ring/29.png  \n",
            "  inflating: dataset/Edge-Ring/3.png  \n",
            "  inflating: dataset/Edge-Ring/30.png  \n",
            "  inflating: dataset/Edge-Ring/31.png  \n",
            "  inflating: dataset/Edge-Ring/32.png  \n",
            "  inflating: dataset/Edge-Ring/33.png  \n",
            "  inflating: dataset/Edge-Ring/34.png  \n",
            "  inflating: dataset/Edge-Ring/35.png  \n",
            "  inflating: dataset/Edge-Ring/36.png  \n",
            "  inflating: dataset/Edge-Ring/37.png  \n",
            "  inflating: dataset/Edge-Ring/38.png  \n",
            "  inflating: dataset/Edge-Ring/39.png  \n",
            "  inflating: dataset/Edge-Ring/4.png  \n",
            "  inflating: dataset/Edge-Ring/40.png  \n",
            "  inflating: dataset/Edge-Ring/41.png  \n",
            "  inflating: dataset/Edge-Ring/42.png  \n",
            "  inflating: dataset/Edge-Ring/43.png  \n",
            "  inflating: dataset/Edge-Ring/44.png  \n",
            "  inflating: dataset/Edge-Ring/45.png  \n",
            "  inflating: dataset/Edge-Ring/46.png  \n",
            "  inflating: dataset/Edge-Ring/47.png  \n",
            "  inflating: dataset/Edge-Ring/48.png  \n",
            "  inflating: dataset/Edge-Ring/49.png  \n",
            "  inflating: dataset/Edge-Ring/5.png  \n",
            "  inflating: dataset/Edge-Ring/50.png  \n",
            "  inflating: dataset/Edge-Ring/51.png  \n",
            "  inflating: dataset/Edge-Ring/52.png  \n",
            "  inflating: dataset/Edge-Ring/53.png  \n",
            "  inflating: dataset/Edge-Ring/54.png  \n",
            "  inflating: dataset/Edge-Ring/55.png  \n",
            "  inflating: dataset/Edge-Ring/56.png  \n",
            "  inflating: dataset/Edge-Ring/57.png  \n",
            "  inflating: dataset/Edge-Ring/58.png  \n",
            "  inflating: dataset/Edge-Ring/59.png  \n",
            "  inflating: dataset/Edge-Ring/6.png  \n",
            "  inflating: dataset/Edge-Ring/60.png  \n",
            "  inflating: dataset/Edge-Ring/61.png  \n",
            "  inflating: dataset/Edge-Ring/62.png  \n",
            "  inflating: dataset/Edge-Ring/63.png  \n",
            "  inflating: dataset/Edge-Ring/64.png  \n",
            "  inflating: dataset/Edge-Ring/65.png  \n",
            "  inflating: dataset/Edge-Ring/66.png  \n",
            "  inflating: dataset/Edge-Ring/67.png  \n",
            "  inflating: dataset/Edge-Ring/68.png  \n",
            "  inflating: dataset/Edge-Ring/69.png  \n",
            "  inflating: dataset/Edge-Ring/7.png  \n",
            "  inflating: dataset/Edge-Ring/70.png  \n",
            "  inflating: dataset/Edge-Ring/71.png  \n",
            "  inflating: dataset/Edge-Ring/72.png  \n",
            "  inflating: dataset/Edge-Ring/73.png  \n",
            "  inflating: dataset/Edge-Ring/74.png  \n",
            "  inflating: dataset/Edge-Ring/75.png  \n",
            "  inflating: dataset/Edge-Ring/76.png  \n",
            "  inflating: dataset/Edge-Ring/77.png  \n",
            "  inflating: dataset/Edge-Ring/78.png  \n",
            "  inflating: dataset/Edge-Ring/79.png  \n",
            "  inflating: dataset/Edge-Ring/8.png  \n",
            "  inflating: dataset/Edge-Ring/80.png  \n",
            "  inflating: dataset/Edge-Ring/81.png  \n",
            "  inflating: dataset/Edge-Ring/82.png  \n",
            "  inflating: dataset/Edge-Ring/83.png  \n",
            "  inflating: dataset/Edge-Ring/84.png  \n",
            "  inflating: dataset/Edge-Ring/85.png  \n",
            "  inflating: dataset/Edge-Ring/86.png  \n",
            "  inflating: dataset/Edge-Ring/87.png  \n",
            "  inflating: dataset/Edge-Ring/88.png  \n",
            "  inflating: dataset/Edge-Ring/89.png  \n",
            "  inflating: dataset/Edge-Ring/9.png  \n",
            "  inflating: dataset/Edge-Ring/90.png  \n",
            "  inflating: dataset/Edge-Ring/91.png  \n",
            "  inflating: dataset/Edge-Ring/92.png  \n",
            "  inflating: dataset/Edge-Ring/93.png  \n",
            "  inflating: dataset/Edge-Ring/94.png  \n",
            "  inflating: dataset/Edge-Ring/95.png  \n",
            "  inflating: dataset/Edge-Ring/96.png  \n",
            "  inflating: dataset/Edge-Ring/97.png  \n",
            "  inflating: dataset/Edge-Ring/98.png  \n",
            "  inflating: dataset/Edge-Ring/99.png  \n",
            "   creating: dataset/Loc/\n",
            "  inflating: dataset/Loc/0.png       \n",
            "  inflating: dataset/Loc/1.png       \n",
            "  inflating: dataset/Loc/10.png      \n",
            "  inflating: dataset/Loc/100.png     \n",
            "  inflating: dataset/Loc/101.png     \n",
            "  inflating: dataset/Loc/102.png     \n",
            "  inflating: dataset/Loc/103.png     \n",
            "  inflating: dataset/Loc/104.png     \n",
            "  inflating: dataset/Loc/105.png     \n",
            "  inflating: dataset/Loc/106.png     \n",
            "  inflating: dataset/Loc/107.png     \n",
            "  inflating: dataset/Loc/108.png     \n",
            "  inflating: dataset/Loc/109.png     \n",
            "  inflating: dataset/Loc/11.png      \n",
            "  inflating: dataset/Loc/110.png     \n",
            "  inflating: dataset/Loc/111.png     \n",
            "  inflating: dataset/Loc/112.png     \n",
            "  inflating: dataset/Loc/113.png     \n",
            "  inflating: dataset/Loc/114.png     \n",
            "  inflating: dataset/Loc/115.png     \n",
            "  inflating: dataset/Loc/116.png     \n",
            "  inflating: dataset/Loc/117.png     \n",
            "  inflating: dataset/Loc/118.png     \n",
            "  inflating: dataset/Loc/119.png     \n",
            "  inflating: dataset/Loc/12.png      \n",
            "  inflating: dataset/Loc/13.png      \n",
            "  inflating: dataset/Loc/14.png      \n",
            "  inflating: dataset/Loc/15.png      \n",
            "  inflating: dataset/Loc/16.png      \n",
            "  inflating: dataset/Loc/17.png      \n",
            "  inflating: dataset/Loc/18.png      \n",
            "  inflating: dataset/Loc/19.png      \n",
            "  inflating: dataset/Loc/2.png       \n",
            "  inflating: dataset/Loc/20.png      \n",
            "  inflating: dataset/Loc/21.png      \n",
            "  inflating: dataset/Loc/22.png      \n",
            "  inflating: dataset/Loc/23.png      \n",
            "  inflating: dataset/Loc/24.png      \n",
            "  inflating: dataset/Loc/25.png      \n",
            "  inflating: dataset/Loc/26.png      \n",
            "  inflating: dataset/Loc/27.png      \n",
            "  inflating: dataset/Loc/28.png      \n",
            "  inflating: dataset/Loc/29.png      \n",
            "  inflating: dataset/Loc/3.png       \n",
            "  inflating: dataset/Loc/30.png      \n",
            "  inflating: dataset/Loc/31.png      \n",
            "  inflating: dataset/Loc/32.png      \n",
            "  inflating: dataset/Loc/33.png      \n",
            "  inflating: dataset/Loc/34.png      \n",
            "  inflating: dataset/Loc/35.png      \n",
            "  inflating: dataset/Loc/36.png      \n",
            "  inflating: dataset/Loc/37.png      \n",
            "  inflating: dataset/Loc/38.png      \n",
            "  inflating: dataset/Loc/39.png      \n",
            "  inflating: dataset/Loc/4.png       \n",
            "  inflating: dataset/Loc/40.png      \n",
            "  inflating: dataset/Loc/41.png      \n",
            "  inflating: dataset/Loc/42.png      \n",
            "  inflating: dataset/Loc/43.png      \n",
            "  inflating: dataset/Loc/44.png      \n",
            "  inflating: dataset/Loc/45.png      \n",
            "  inflating: dataset/Loc/46.png      \n",
            "  inflating: dataset/Loc/47.png      \n",
            "  inflating: dataset/Loc/48.png      \n",
            "  inflating: dataset/Loc/49.png      \n",
            "  inflating: dataset/Loc/5.png       \n",
            "  inflating: dataset/Loc/50.png      \n",
            "  inflating: dataset/Loc/51.png      \n",
            "  inflating: dataset/Loc/52.png      \n",
            "  inflating: dataset/Loc/53.png      \n",
            "  inflating: dataset/Loc/54.png      \n",
            "  inflating: dataset/Loc/55.png      \n",
            "  inflating: dataset/Loc/56.png      \n",
            "  inflating: dataset/Loc/57.png      \n",
            "  inflating: dataset/Loc/58.png      \n",
            "  inflating: dataset/Loc/59.png      \n",
            "  inflating: dataset/Loc/6.png       \n",
            "  inflating: dataset/Loc/60.png      \n",
            "  inflating: dataset/Loc/61.png      \n",
            "  inflating: dataset/Loc/62.png      \n",
            "  inflating: dataset/Loc/63.png      \n",
            "  inflating: dataset/Loc/64.png      \n",
            "  inflating: dataset/Loc/65.png      \n",
            "  inflating: dataset/Loc/66.png      \n",
            "  inflating: dataset/Loc/67.png      \n",
            "  inflating: dataset/Loc/68.png      \n",
            "  inflating: dataset/Loc/69.png      \n",
            "  inflating: dataset/Loc/7.png       \n",
            "  inflating: dataset/Loc/70.png      \n",
            "  inflating: dataset/Loc/71.png      \n",
            "  inflating: dataset/Loc/72.png      \n",
            "  inflating: dataset/Loc/73.png      \n",
            "  inflating: dataset/Loc/74.png      \n",
            "  inflating: dataset/Loc/75.png      \n",
            "  inflating: dataset/Loc/76.png      \n",
            "  inflating: dataset/Loc/77.png      \n",
            "  inflating: dataset/Loc/78.png      \n",
            "  inflating: dataset/Loc/79.png      \n",
            "  inflating: dataset/Loc/8.png       \n",
            "  inflating: dataset/Loc/80.png      \n",
            "  inflating: dataset/Loc/81.png      \n",
            "  inflating: dataset/Loc/82.png      \n",
            "  inflating: dataset/Loc/83.png      \n",
            "  inflating: dataset/Loc/84.png      \n",
            "  inflating: dataset/Loc/85.png      \n",
            "  inflating: dataset/Loc/86.png      \n",
            "  inflating: dataset/Loc/87.png      \n",
            "  inflating: dataset/Loc/88.png      \n",
            "  inflating: dataset/Loc/89.png      \n",
            "  inflating: dataset/Loc/9.png       \n",
            "  inflating: dataset/Loc/90.png      \n",
            "  inflating: dataset/Loc/91.png      \n",
            "  inflating: dataset/Loc/92.png      \n",
            "  inflating: dataset/Loc/93.png      \n",
            "  inflating: dataset/Loc/94.png      \n",
            "  inflating: dataset/Loc/95.png      \n",
            "  inflating: dataset/Loc/96.png      \n",
            "  inflating: dataset/Loc/97.png      \n",
            "  inflating: dataset/Loc/98.png      \n",
            "  inflating: dataset/Loc/99.png      \n",
            "   creating: dataset/Random/\n",
            "  inflating: dataset/Random/0.png    \n",
            "  inflating: dataset/Random/1.png    \n",
            "  inflating: dataset/Random/10.png   \n",
            "  inflating: dataset/Random/100.png  \n",
            "  inflating: dataset/Random/101.png  \n",
            "  inflating: dataset/Random/102.png  \n",
            "  inflating: dataset/Random/103.png  \n",
            "  inflating: dataset/Random/104.png  \n",
            "  inflating: dataset/Random/105.png  \n",
            "  inflating: dataset/Random/106.png  \n",
            "  inflating: dataset/Random/107.png  \n",
            "  inflating: dataset/Random/108.png  \n",
            "  inflating: dataset/Random/109.png  \n",
            "  inflating: dataset/Random/11.png   \n",
            "  inflating: dataset/Random/110.png  \n",
            "  inflating: dataset/Random/111.png  \n",
            "  inflating: dataset/Random/112.png  \n",
            "  inflating: dataset/Random/113.png  \n",
            "  inflating: dataset/Random/114.png  \n",
            "  inflating: dataset/Random/115.png  \n",
            "  inflating: dataset/Random/116.png  \n",
            "  inflating: dataset/Random/117.png  \n",
            "  inflating: dataset/Random/118.png  \n",
            "  inflating: dataset/Random/119.png  \n",
            "  inflating: dataset/Random/12.png   \n",
            "  inflating: dataset/Random/13.png   \n",
            "  inflating: dataset/Random/14.png   \n",
            "  inflating: dataset/Random/15.png   \n",
            "  inflating: dataset/Random/16.png   \n",
            "  inflating: dataset/Random/17.png   \n",
            "  inflating: dataset/Random/18.png   \n",
            "  inflating: dataset/Random/19.png   \n",
            "  inflating: dataset/Random/2.png    \n",
            "  inflating: dataset/Random/20.png   \n",
            "  inflating: dataset/Random/21.png   \n",
            "  inflating: dataset/Random/22.png   \n",
            "  inflating: dataset/Random/23.png   \n",
            "  inflating: dataset/Random/24.png   \n",
            "  inflating: dataset/Random/25.png   \n",
            "  inflating: dataset/Random/26.png   \n",
            "  inflating: dataset/Random/27.png   \n",
            "  inflating: dataset/Random/28.png   \n",
            "  inflating: dataset/Random/29.png   \n",
            "  inflating: dataset/Random/3.png    \n",
            "  inflating: dataset/Random/30.png   \n",
            "  inflating: dataset/Random/31.png   \n",
            "  inflating: dataset/Random/32.png   \n",
            "  inflating: dataset/Random/33.png   \n",
            "  inflating: dataset/Random/34.png   \n",
            "  inflating: dataset/Random/35.png   \n",
            "  inflating: dataset/Random/36.png   \n",
            "  inflating: dataset/Random/37.png   \n",
            "  inflating: dataset/Random/38.png   \n",
            "  inflating: dataset/Random/39.png   \n",
            "  inflating: dataset/Random/4.png    \n",
            "  inflating: dataset/Random/40.png   \n",
            "  inflating: dataset/Random/41.png   \n",
            "  inflating: dataset/Random/42.png   \n",
            "  inflating: dataset/Random/43.png   \n",
            "  inflating: dataset/Random/44.png   \n",
            "  inflating: dataset/Random/45.png   \n",
            "  inflating: dataset/Random/46.png   \n",
            "  inflating: dataset/Random/47.png   \n",
            "  inflating: dataset/Random/48.png   \n",
            "  inflating: dataset/Random/49.png   \n",
            "  inflating: dataset/Random/5.png    \n",
            "  inflating: dataset/Random/50.png   \n",
            "  inflating: dataset/Random/51.png   \n",
            "  inflating: dataset/Random/52.png   \n",
            "  inflating: dataset/Random/53.png   \n",
            "  inflating: dataset/Random/54.png   \n",
            "  inflating: dataset/Random/55.png   \n",
            "  inflating: dataset/Random/56.png   \n",
            "  inflating: dataset/Random/57.png   \n",
            "  inflating: dataset/Random/58.png   \n",
            "  inflating: dataset/Random/59.png   \n",
            "  inflating: dataset/Random/6.png    \n",
            "  inflating: dataset/Random/60.png   \n",
            "  inflating: dataset/Random/61.png   \n",
            "  inflating: dataset/Random/62.png   \n",
            "  inflating: dataset/Random/63.png   \n",
            "  inflating: dataset/Random/64.png   \n",
            "  inflating: dataset/Random/65.png   \n",
            "  inflating: dataset/Random/66.png   \n",
            "  inflating: dataset/Random/67.png   \n",
            "  inflating: dataset/Random/68.png   \n",
            "  inflating: dataset/Random/69.png   \n",
            "  inflating: dataset/Random/7.png    \n",
            "  inflating: dataset/Random/70.png   \n",
            "  inflating: dataset/Random/71.png   \n",
            "  inflating: dataset/Random/72.png   \n",
            "  inflating: dataset/Random/73.png   \n",
            "  inflating: dataset/Random/74.png   \n",
            "  inflating: dataset/Random/75.png   \n",
            "  inflating: dataset/Random/76.png   \n",
            "  inflating: dataset/Random/77.png   \n",
            "  inflating: dataset/Random/78.png   \n",
            "  inflating: dataset/Random/79.png   \n",
            "  inflating: dataset/Random/8.png    \n",
            "  inflating: dataset/Random/80.png   \n",
            "  inflating: dataset/Random/81.png   \n",
            "  inflating: dataset/Random/82.png   \n",
            "  inflating: dataset/Random/83.png   \n",
            "  inflating: dataset/Random/84.png   \n",
            "  inflating: dataset/Random/85.png   \n",
            "  inflating: dataset/Random/86.png   \n",
            "  inflating: dataset/Random/87.png   \n",
            "  inflating: dataset/Random/88.png   \n",
            "  inflating: dataset/Random/89.png   \n",
            "  inflating: dataset/Random/9.png    \n",
            "  inflating: dataset/Random/90.png   \n",
            "  inflating: dataset/Random/91.png   \n",
            "  inflating: dataset/Random/92.png   \n",
            "  inflating: dataset/Random/93.png   \n",
            "  inflating: dataset/Random/94.png   \n",
            "  inflating: dataset/Random/95.png   \n",
            "  inflating: dataset/Random/96.png   \n",
            "  inflating: dataset/Random/97.png   \n",
            "  inflating: dataset/Random/98.png   \n",
            "  inflating: dataset/Random/99.png   \n",
            "   creating: dataset/Scratch/\n",
            "  inflating: dataset/Scratch/0.png   \n",
            "  inflating: dataset/Scratch/1.png   \n",
            "  inflating: dataset/Scratch/10.png  \n",
            "  inflating: dataset/Scratch/100.png  \n",
            "  inflating: dataset/Scratch/101.png  \n",
            "  inflating: dataset/Scratch/102.png  \n",
            "  inflating: dataset/Scratch/103.png  \n",
            "  inflating: dataset/Scratch/104.png  \n",
            "  inflating: dataset/Scratch/105.png  \n",
            "  inflating: dataset/Scratch/106.png  \n",
            "  inflating: dataset/Scratch/107.png  \n",
            "  inflating: dataset/Scratch/108.png  \n",
            "  inflating: dataset/Scratch/109.png  \n",
            "  inflating: dataset/Scratch/11.png  \n",
            "  inflating: dataset/Scratch/110.png  \n",
            "  inflating: dataset/Scratch/111.png  \n",
            "  inflating: dataset/Scratch/112.png  \n",
            "  inflating: dataset/Scratch/113.png  \n",
            "  inflating: dataset/Scratch/114.png  \n",
            "  inflating: dataset/Scratch/115.png  \n",
            "  inflating: dataset/Scratch/116.png  \n",
            "  inflating: dataset/Scratch/117.png  \n",
            "  inflating: dataset/Scratch/118.png  \n",
            "  inflating: dataset/Scratch/119.png  \n",
            "  inflating: dataset/Scratch/12.png  \n",
            "  inflating: dataset/Scratch/13.png  \n",
            "  inflating: dataset/Scratch/14.png  \n",
            "  inflating: dataset/Scratch/15.png  \n",
            "  inflating: dataset/Scratch/16.png  \n",
            "  inflating: dataset/Scratch/17.png  \n",
            "  inflating: dataset/Scratch/18.png  \n",
            "  inflating: dataset/Scratch/19.png  \n",
            "  inflating: dataset/Scratch/2.png   \n",
            "  inflating: dataset/Scratch/20.png  \n",
            "  inflating: dataset/Scratch/21.png  \n",
            "  inflating: dataset/Scratch/22.png  \n",
            "  inflating: dataset/Scratch/23.png  \n",
            "  inflating: dataset/Scratch/24.png  \n",
            "  inflating: dataset/Scratch/25.png  \n",
            "  inflating: dataset/Scratch/26.png  \n",
            "  inflating: dataset/Scratch/27.png  \n",
            "  inflating: dataset/Scratch/28.png  \n",
            "  inflating: dataset/Scratch/29.png  \n",
            "  inflating: dataset/Scratch/3.png   \n",
            "  inflating: dataset/Scratch/30.png  \n",
            "  inflating: dataset/Scratch/31.png  \n",
            "  inflating: dataset/Scratch/32.png  \n",
            "  inflating: dataset/Scratch/33.png  \n",
            "  inflating: dataset/Scratch/34.png  \n",
            "  inflating: dataset/Scratch/35.png  \n",
            "  inflating: dataset/Scratch/36.png  \n",
            "  inflating: dataset/Scratch/37.png  \n",
            "  inflating: dataset/Scratch/38.png  \n",
            "  inflating: dataset/Scratch/39.png  \n",
            "  inflating: dataset/Scratch/4.png   \n",
            "  inflating: dataset/Scratch/40.png  \n",
            "  inflating: dataset/Scratch/41.png  \n",
            "  inflating: dataset/Scratch/42.png  \n",
            "  inflating: dataset/Scratch/43.png  \n",
            "  inflating: dataset/Scratch/44.png  \n",
            "  inflating: dataset/Scratch/45.png  \n",
            "  inflating: dataset/Scratch/46.png  \n",
            "  inflating: dataset/Scratch/47.png  \n",
            "  inflating: dataset/Scratch/48.png  \n",
            "  inflating: dataset/Scratch/49.png  \n",
            "  inflating: dataset/Scratch/5.png   \n",
            "  inflating: dataset/Scratch/50.png  \n",
            "  inflating: dataset/Scratch/51.png  \n",
            "  inflating: dataset/Scratch/52.png  \n",
            "  inflating: dataset/Scratch/53.png  \n",
            "  inflating: dataset/Scratch/54.png  \n",
            "  inflating: dataset/Scratch/55.png  \n",
            "  inflating: dataset/Scratch/56.png  \n",
            "  inflating: dataset/Scratch/57.png  \n",
            "  inflating: dataset/Scratch/58.png  \n",
            "  inflating: dataset/Scratch/59.png  \n",
            "  inflating: dataset/Scratch/6.png   \n",
            "  inflating: dataset/Scratch/60.png  \n",
            "  inflating: dataset/Scratch/61.png  \n",
            "  inflating: dataset/Scratch/62.png  \n",
            "  inflating: dataset/Scratch/63.png  \n",
            "  inflating: dataset/Scratch/64.png  \n",
            "  inflating: dataset/Scratch/65.png  \n",
            "  inflating: dataset/Scratch/66.png  \n",
            "  inflating: dataset/Scratch/67.png  \n",
            "  inflating: dataset/Scratch/68.png  \n",
            "  inflating: dataset/Scratch/69.png  \n",
            "  inflating: dataset/Scratch/7.png   \n",
            "  inflating: dataset/Scratch/70.png  \n",
            "  inflating: dataset/Scratch/71.png  \n",
            "  inflating: dataset/Scratch/72.png  \n",
            "  inflating: dataset/Scratch/73.png  \n",
            "  inflating: dataset/Scratch/74.png  \n",
            "  inflating: dataset/Scratch/75.png  \n",
            "  inflating: dataset/Scratch/76.png  \n",
            "  inflating: dataset/Scratch/77.png  \n",
            "  inflating: dataset/Scratch/78.png  \n",
            "  inflating: dataset/Scratch/79.png  \n",
            "  inflating: dataset/Scratch/8.png   \n",
            "  inflating: dataset/Scratch/80.png  \n",
            "  inflating: dataset/Scratch/81.png  \n",
            "  inflating: dataset/Scratch/82.png  \n",
            "  inflating: dataset/Scratch/83.png  \n",
            "  inflating: dataset/Scratch/84.png  \n",
            "  inflating: dataset/Scratch/85.png  \n",
            "  inflating: dataset/Scratch/86.png  \n",
            "  inflating: dataset/Scratch/87.png  \n",
            "  inflating: dataset/Scratch/88.png  \n",
            "  inflating: dataset/Scratch/89.png  \n",
            "  inflating: dataset/Scratch/9.png   \n",
            "  inflating: dataset/Scratch/90.png  \n",
            "  inflating: dataset/Scratch/91.png  \n",
            "  inflating: dataset/Scratch/92.png  \n",
            "  inflating: dataset/Scratch/93.png  \n",
            "  inflating: dataset/Scratch/94.png  \n",
            "  inflating: dataset/Scratch/95.png  \n",
            "  inflating: dataset/Scratch/96.png  \n",
            "  inflating: dataset/Scratch/97.png  \n",
            "  inflating: dataset/Scratch/98.png  \n",
            "  inflating: dataset/Scratch/99.png  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls dataset\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcQ_23cI2oei",
        "outputId": "6fdb5daf-7b08-4233-a93e-9bf7c617091b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Center\tDonut  Edge-Loc  Edge-Ring  Loc  Random  Scratch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Prepare data\n",
        "data = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "train = data.flow_from_directory(\n",
        "    \"dataset\",\n",
        "    target_size=(224,224),\n",
        "    subset=\"training\"\n",
        ")\n",
        "\n",
        "val = data.flow_from_directory(\n",
        "    \"dataset\",\n",
        "    target_size=(224,224),\n",
        "    subset=\"validation\"\n",
        ")\n",
        "\n",
        "# Load MobileNetV2\n",
        "base_model = tf.keras.applications.MobileNetV2(\n",
        "    input_shape=(224,224,3),\n",
        "    include_top=False,\n",
        "    weights='imagenet'\n",
        ")\n",
        "\n",
        "base_model.trainable = False\n",
        "\n",
        "# Add classifier\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
        "output = tf.keras.layers.Dense(train.num_classes, activation='softmax')(x)\n",
        "\n",
        "model = tf.keras.Model(base_model.input, output)\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Train\n",
        "model.fit(train, validation_data=val, epochs=5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUrrhcVV2zEy",
        "outputId": "23446c03-e6cb-4632-eaca-375b115ec0fc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 672 images belonging to 7 classes.\n",
            "Found 168 images belonging to 7 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 842ms/step - accuracy: 0.1942 - loss: 2.0962 - val_accuracy: 0.4464 - val_loss: 1.5557\n",
            "Epoch 2/5\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 170ms/step - accuracy: 0.4866 - loss: 1.4892 - val_accuracy: 0.5476 - val_loss: 1.3856\n",
            "Epoch 3/5\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - accuracy: 0.5190 - loss: 1.3287 - val_accuracy: 0.5536 - val_loss: 1.2767\n",
            "Epoch 4/5\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - accuracy: 0.5785 - loss: 1.1892 - val_accuracy: 0.5476 - val_loss: 1.2133\n",
            "Epoch 5/5\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 123ms/step - accuracy: 0.6318 - loss: 1.0838 - val_accuracy: 0.5417 - val_loss: 1.1848\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7aee26679b20>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unfreeze some layers\n",
        "base_model.trainable = True\n",
        "\n",
        "# freeze first 100 layers only\n",
        "for layer in base_model.layers[:100]:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-5),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.fit(train, validation_data=val, epochs=5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZcEmD-MD3_Fm",
        "outputId": "1d7a6000-8dc1-488c-c8ec-72b25efe2e54"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 514ms/step - accuracy: 0.1844 - loss: 3.4211 - val_accuracy: 0.5536 - val_loss: 1.1964\n",
            "Epoch 2/5\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 188ms/step - accuracy: 0.2837 - loss: 2.5100 - val_accuracy: 0.5655 - val_loss: 1.2161\n",
            "Epoch 3/5\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - accuracy: 0.3885 - loss: 1.7458 - val_accuracy: 0.5238 - val_loss: 1.2509\n",
            "Epoch 4/5\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - accuracy: 0.4803 - loss: 1.3960 - val_accuracy: 0.5000 - val_loss: 1.2891\n",
            "Epoch 5/5\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - accuracy: 0.5754 - loss: 1.2071 - val_accuracy: 0.5119 - val_loss: 1.3169\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7aee200ee570>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "data = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.2,\n",
        "    rotation_range=20,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "train = data.flow_from_directory(\n",
        "    \"dataset\",\n",
        "    target_size=(224,224),\n",
        "    subset=\"training\"\n",
        ")\n",
        "\n",
        "val = data.flow_from_directory(\n",
        "    \"dataset\",\n",
        "    target_size=(224,224),\n",
        "    subset=\"validation\"\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJohg7SS4X87",
        "outputId": "87162e35-820f-46a0-ef81-f4f0876196ac"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 672 images belonging to 7 classes.\n",
            "Found 168 images belonging to 7 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train, validation_data=val, epochs=8)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oio1f6sv4eY7",
        "outputId": "8fa6836a-8277-49f8-b2f7-f37c4d4da4dd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 592ms/step - accuracy: 0.3753 - loss: 1.8187 - val_accuracy: 0.3214 - val_loss: 2.4342\n",
            "Epoch 2/8\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 524ms/step - accuracy: 0.4440 - loss: 1.4716 - val_accuracy: 0.3214 - val_loss: 2.2987\n",
            "Epoch 3/8\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 507ms/step - accuracy: 0.5184 - loss: 1.3177 - val_accuracy: 0.3095 - val_loss: 2.2696\n",
            "Epoch 4/8\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 553ms/step - accuracy: 0.4922 - loss: 1.3210 - val_accuracy: 0.3393 - val_loss: 2.2117\n",
            "Epoch 5/8\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 557ms/step - accuracy: 0.5339 - loss: 1.2463 - val_accuracy: 0.3750 - val_loss: 2.1767\n",
            "Epoch 6/8\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 559ms/step - accuracy: 0.5549 - loss: 1.1969 - val_accuracy: 0.3214 - val_loss: 2.0783\n",
            "Epoch 7/8\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 557ms/step - accuracy: 0.5776 - loss: 1.1666 - val_accuracy: 0.3512 - val_loss: 2.1308\n",
            "Epoch 8/8\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 555ms/step - accuracy: 0.5557 - loss: 1.1526 - val_accuracy: 0.3988 - val_loss: 1.9439\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7aed920288f0>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "keep = [\"Center\",\"Donut\",\"Scratch\",\"Edge-Ring\"]\n",
        "\n",
        "for folder in os.listdir(\"dataset\"):\n",
        "    if folder not in keep:\n",
        "        shutil.rmtree(f\"dataset/{folder}\")\n"
      ],
      "metadata": {
        "id": "eCuaGliu5Qso"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "data = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.2,\n",
        "    rotation_range=25,\n",
        "    zoom_range=0.3,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "train = data.flow_from_directory(\n",
        "    \"dataset\",\n",
        "    target_size=(224,224),\n",
        "    subset=\"training\"\n",
        ")\n",
        "\n",
        "val = data.flow_from_directory(\n",
        "    \"dataset\",\n",
        "    target_size=(224,224),\n",
        "    subset=\"validation\"\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTr64F0_5Sud",
        "outputId": "4ff20aa6-2504-4640-d8a2-aa5c11b62d62"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 384 images belonging to 4 classes.\n",
            "Found 96 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = tf.keras.applications.MobileNetV2(\n",
        "    input_shape=(224,224,3),\n",
        "    include_top=False,\n",
        "    weights='imagenet'\n",
        ")\n",
        "\n",
        "base_model.trainable = False\n",
        "\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
        "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
        "output = tf.keras.layers.Dense(train.num_classes, activation='softmax')(x)\n",
        "\n",
        "model = tf.keras.Model(base_model.input, output)\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n"
      ],
      "metadata": {
        "id": "aVSKM97y5ay1"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train, validation_data=val, epochs=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOdxa34c5e9S",
        "outputId": "c8def16b-ef58-4b6d-fbd6-c97ce8b92bbf"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 0.4563 - loss: 1.2855 - val_accuracy: 0.6562 - val_loss: 0.9140\n",
            "Epoch 2/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 621ms/step - accuracy: 0.6929 - loss: 0.8071 - val_accuracy: 0.6354 - val_loss: 0.9451\n",
            "Epoch 3/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 494ms/step - accuracy: 0.7653 - loss: 0.6444 - val_accuracy: 0.6771 - val_loss: 0.8990\n",
            "Epoch 4/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 629ms/step - accuracy: 0.7161 - loss: 0.7264 - val_accuracy: 0.7396 - val_loss: 0.7150\n",
            "Epoch 5/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 494ms/step - accuracy: 0.7738 - loss: 0.6191 - val_accuracy: 0.6979 - val_loss: 0.7197\n",
            "Epoch 6/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 628ms/step - accuracy: 0.7951 - loss: 0.5258 - val_accuracy: 0.8125 - val_loss: 0.5684\n",
            "Epoch 7/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 500ms/step - accuracy: 0.8066 - loss: 0.5228 - val_accuracy: 0.7292 - val_loss: 0.6954\n",
            "Epoch 8/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 618ms/step - accuracy: 0.8184 - loss: 0.4987 - val_accuracy: 0.7708 - val_loss: 0.6342\n",
            "Epoch 9/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 501ms/step - accuracy: 0.8288 - loss: 0.5097 - val_accuracy: 0.7396 - val_loss: 0.7348\n",
            "Epoch 10/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 618ms/step - accuracy: 0.8229 - loss: 0.4597 - val_accuracy: 0.7708 - val_loss: 0.6780\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7aed89f08470>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train, validation_data=val, epochs=5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTExotYM5_V-",
        "outputId": "f29116e6-f708-40d7-9789-1b983bddee2a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 578ms/step - accuracy: 0.8382 - loss: 0.4406 - val_accuracy: 0.7188 - val_loss: 0.6732\n",
            "Epoch 2/5\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 627ms/step - accuracy: 0.8261 - loss: 0.4165 - val_accuracy: 0.7292 - val_loss: 0.6913\n",
            "Epoch 3/5\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 498ms/step - accuracy: 0.8232 - loss: 0.4187 - val_accuracy: 0.7396 - val_loss: 0.6855\n",
            "Epoch 4/5\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 620ms/step - accuracy: 0.8316 - loss: 0.4526 - val_accuracy: 0.7604 - val_loss: 0.6645\n",
            "Epoch 5/5\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 490ms/step - accuracy: 0.8454 - loss: 0.4056 - val_accuracy: 0.8021 - val_loss: 0.5354\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7aed8969d340>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unfreeze last layers\n",
        "base_model.trainable = True\n",
        "\n",
        "for layer in base_model.layers[:-30]:\n",
        "    layer.trainable = False\n"
      ],
      "metadata": {
        "id": "6_1N5DhW6jvv"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-5),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n"
      ],
      "metadata": {
        "id": "DX9t47Uy6plz"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "data = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.2,\n",
        "    rotation_range=30,\n",
        "    zoom_range=0.35,\n",
        "    width_shift_range=0.25,\n",
        "    height_shift_range=0.25,\n",
        "    brightness_range=[0.8,1.2],\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "train = data.flow_from_directory(\n",
        "    \"dataset\",\n",
        "    target_size=(224,224),\n",
        "    subset=\"training\"\n",
        ")\n",
        "\n",
        "val = data.flow_from_directory(\n",
        "    \"dataset\",\n",
        "    target_size=(224,224),\n",
        "    subset=\"validation\"\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zG1c3pgs6xan",
        "outputId": "7d0ac84c-98ed-48f5-927c-4717a890804b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 384 images belonging to 4 classes.\n",
            "Found 96 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "callback = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_accuracy\",\n",
        "    patience=3,\n",
        "    restore_best_weights=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "TN-XU0vA7EWp"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "    train,\n",
        "    validation_data=val,\n",
        "    epochs=15,\n",
        "    callbacks=[callback]\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvgAMQub7Hl9",
        "outputId": "89d13625-96f6-4d9c-8441-a90a91bd6193"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 1s/step - accuracy: 0.4474 - loss: 2.5796 - val_accuracy: 0.7083 - val_loss: 0.7701\n",
            "Epoch 2/15\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 692ms/step - accuracy: 0.5150 - loss: 1.8111 - val_accuracy: 0.7812 - val_loss: 0.6018\n",
            "Epoch 3/15\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 567ms/step - accuracy: 0.5700 - loss: 1.3487 - val_accuracy: 0.7500 - val_loss: 0.7635\n",
            "Epoch 4/15\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 686ms/step - accuracy: 0.6568 - loss: 0.9832 - val_accuracy: 0.7292 - val_loss: 0.8544\n",
            "Epoch 5/15\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 567ms/step - accuracy: 0.7096 - loss: 0.7817 - val_accuracy: 0.7188 - val_loss: 0.8177\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7aee200f5af0>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = data.flow_from_directory(\n",
        "    \"dataset\",\n",
        "    target_size=(256,256),\n",
        "    subset=\"training\"\n",
        ")\n",
        "\n",
        "val = data.flow_from_directory(\n",
        "    \"dataset\",\n",
        "    target_size=(256,256),\n",
        "    subset=\"validation\"\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVOgCbrn7rPL",
        "outputId": "5f242afa-74c4-44e3-ee22-bf6923fb178d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 384 images belonging to 4 classes.\n",
            "Found 96 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = tf.keras.applications.MobileNetV2(\n",
        "    input_shape=(256,256,3),\n",
        "    include_top=False,\n",
        "    weights='imagenet'\n",
        ")\n",
        "\n",
        "base_model.trainable = False\n",
        "\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
        "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
        "output = tf.keras.layers.Dense(train.num_classes, activation='softmax')(x)\n",
        "\n",
        "model = tf.keras.Model(base_model.input, output)\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_rcYCp_7w-2",
        "outputId": "565b8931-f577-4ff3-958a-40cc6342265c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-514573126.py:1: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "  base_model = tf.keras.applications.MobileNetV2(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train, validation_data=val, epochs=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDU7b8by71Zr",
        "outputId": "8d3ca358-c67f-4cfb-bd1d-5d42ad1b9b77"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1s/step - accuracy: 0.3789 - loss: 1.5952 - val_accuracy: 0.6562 - val_loss: 0.9617\n",
            "Epoch 2/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 774ms/step - accuracy: 0.6613 - loss: 0.8982 - val_accuracy: 0.6354 - val_loss: 0.9103\n",
            "Epoch 3/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 707ms/step - accuracy: 0.6731 - loss: 0.8534 - val_accuracy: 0.7188 - val_loss: 0.7871\n",
            "Epoch 4/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 820ms/step - accuracy: 0.7315 - loss: 0.6999 - val_accuracy: 0.7292 - val_loss: 0.7658\n",
            "Epoch 5/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 811ms/step - accuracy: 0.7467 - loss: 0.6565 - val_accuracy: 0.7188 - val_loss: 0.7238\n",
            "Epoch 6/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 689ms/step - accuracy: 0.7661 - loss: 0.6120 - val_accuracy: 0.7604 - val_loss: 0.6867\n",
            "Epoch 7/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 826ms/step - accuracy: 0.8033 - loss: 0.5848 - val_accuracy: 0.7812 - val_loss: 0.7224\n",
            "Epoch 8/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 820ms/step - accuracy: 0.7567 - loss: 0.6557 - val_accuracy: 0.6979 - val_loss: 0.7152\n",
            "Epoch 9/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 696ms/step - accuracy: 0.7371 - loss: 0.5972 - val_accuracy: 0.7500 - val_loss: 0.6597\n",
            "Epoch 10/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 815ms/step - accuracy: 0.8442 - loss: 0.5214 - val_accuracy: 0.7396 - val_loss: 0.6846\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7aedf10f00e0>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_weights = {\n",
        "    0:1.0,\n",
        "    1:1.2,\n",
        "    2:1.2,\n",
        "    3:1.3\n",
        "}\n",
        "\n",
        "model.fit(\n",
        "    train,\n",
        "    validation_data=val,\n",
        "    epochs=10,\n",
        "    class_weight=class_weights\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fThRjqgT8fn0",
        "outputId": "8d1b1632-a8ae-44f7-cf99-3490710b4bbe"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 866ms/step - accuracy: 0.7981 - loss: 0.6154 - val_accuracy: 0.7708 - val_loss: 0.6819\n",
            "Epoch 2/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 711ms/step - accuracy: 0.7702 - loss: 0.6592 - val_accuracy: 0.8021 - val_loss: 0.5536\n",
            "Epoch 3/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 764ms/step - accuracy: 0.7845 - loss: 0.5854 - val_accuracy: 0.6979 - val_loss: 0.7471\n",
            "Epoch 4/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 820ms/step - accuracy: 0.7880 - loss: 0.6548 - val_accuracy: 0.8021 - val_loss: 0.6601\n",
            "Epoch 5/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 767ms/step - accuracy: 0.7552 - loss: 0.6622 - val_accuracy: 0.7500 - val_loss: 0.7551\n",
            "Epoch 6/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 702ms/step - accuracy: 0.7959 - loss: 0.5908 - val_accuracy: 0.7708 - val_loss: 0.7323\n",
            "Epoch 7/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 831ms/step - accuracy: 0.8017 - loss: 0.5568 - val_accuracy: 0.7604 - val_loss: 0.6566\n",
            "Epoch 8/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 821ms/step - accuracy: 0.7749 - loss: 0.6182 - val_accuracy: 0.7604 - val_loss: 0.7061\n",
            "Epoch 9/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 701ms/step - accuracy: 0.8271 - loss: 0.6224 - val_accuracy: 0.7604 - val_loss: 0.6758\n",
            "Epoch 10/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 824ms/step - accuracy: 0.7938 - loss: 0.6303 - val_accuracy: 0.7083 - val_loss: 0.7327\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7aedf0b2ac00>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = data.flow_from_directory(\n",
        "    \"dataset\",\n",
        "    target_size=(224,224),\n",
        "    color_mode=\"grayscale\",\n",
        "    subset=\"training\"\n",
        ")\n",
        "\n",
        "val = data.flow_from_directory(\n",
        "    \"dataset\",\n",
        "    target_size=(224,224),\n",
        "    color_mode=\"grayscale\",\n",
        "    subset=\"validation\"\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqwsJ4Er9IRx",
        "outputId": "47fdbf72-a4a0-4872-f14e-304cf172daca"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 384 images belonging to 4 classes.\n",
            "Found 96 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, models\n",
        "\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32,3,activation='relu',input_shape=(224,224,1)),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Conv2D(64,3,activation='relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Conv2D(128,3,activation='relu'),\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(64,activation='relu'),\n",
        "    layers.Dense(4,activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.fit(train, validation_data=val, epochs=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjAIAHta9MeD",
        "outputId": "40fbe6d2-0b5f-4ed7-9c14-094087986c97"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 379ms/step - accuracy: 0.2295 - loss: 1.3898 - val_accuracy: 0.2500 - val_loss: 1.3855\n",
            "Epoch 2/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 360ms/step - accuracy: 0.2549 - loss: 1.3851 - val_accuracy: 0.2500 - val_loss: 1.3857\n",
            "Epoch 3/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 261ms/step - accuracy: 0.2726 - loss: 1.3844 - val_accuracy: 0.2500 - val_loss: 1.3852\n",
            "Epoch 4/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 258ms/step - accuracy: 0.2474 - loss: 1.3840 - val_accuracy: 0.2500 - val_loss: 1.3840\n",
            "Epoch 5/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 258ms/step - accuracy: 0.2443 - loss: 1.3833 - val_accuracy: 0.2396 - val_loss: 1.3827\n",
            "Epoch 6/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 354ms/step - accuracy: 0.2501 - loss: 1.3834 - val_accuracy: 0.2500 - val_loss: 1.3827\n",
            "Epoch 7/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 263ms/step - accuracy: 0.2157 - loss: 1.3835 - val_accuracy: 0.2812 - val_loss: 1.3841\n",
            "Epoch 8/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 265ms/step - accuracy: 0.2214 - loss: 1.3776 - val_accuracy: 0.3958 - val_loss: 1.3754\n",
            "Epoch 9/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 278ms/step - accuracy: 0.3607 - loss: 1.3749 - val_accuracy: 0.2917 - val_loss: 1.3766\n",
            "Epoch 10/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 335ms/step - accuracy: 0.2722 - loss: 1.3728 - val_accuracy: 0.3854 - val_loss: 1.3695\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7aed5bfb5220>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_loss, val_acc = model.evaluate(val)\n",
        "print(\"Validation Accuracy:\", val_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTCHbrAF-JDe",
        "outputId": "335b276a-ac77-406a-c38f-e7a1208b7939"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 195ms/step - accuracy: 0.3529 - loss: 1.3697\n",
            "Validation Accuracy: 0.3541666567325592\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "data = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.2,\n",
        "    rotation_range=25,\n",
        "    zoom_range=0.3,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "train = data.flow_from_directory(\n",
        "    \"dataset\",\n",
        "    target_size=(224,224),\n",
        "    subset=\"training\"\n",
        ")\n",
        "\n",
        "val = data.flow_from_directory(\n",
        "    \"dataset\",\n",
        "    target_size=(224,224),\n",
        "    subset=\"validation\"\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16U4nZ4P-YRR",
        "outputId": "73c57c6e-87aa-486b-ba5d-1a67d4e86955"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 384 images belonging to 4 classes.\n",
            "Found 96 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "base_model = tf.keras.applications.MobileNetV2(\n",
        "    input_shape=(224,224,3),\n",
        "    include_top=False,\n",
        "    weights='imagenet'\n",
        ")\n",
        "\n",
        "base_model.trainable = False\n",
        "\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
        "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
        "output = tf.keras.layers.Dense(train.num_classes, activation='softmax')(x)\n",
        "\n",
        "model = tf.keras.Model(base_model.input, output)\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n"
      ],
      "metadata": {
        "id": "ZulxSYKm-ca5"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
        "    \"best_model.h5\",\n",
        "    monitor=\"val_accuracy\",\n",
        "    save_best_only=True,\n",
        "    mode=\"max\"\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "    train,\n",
        "    validation_data=val,\n",
        "    epochs=10,\n",
        "    callbacks=[checkpoint]\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3eYe4lW-fr1",
        "outputId": "bfcd52c3-d888-4cc6-e31c-e12c437059c1"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344ms/step - accuracy: 0.4465 - loss: 1.2830"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 0.4558 - loss: 1.2684 - val_accuracy: 0.6250 - val_loss: 0.9546\n",
            "Epoch 2/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - accuracy: 0.6543 - loss: 0.8936"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 517ms/step - accuracy: 0.6574 - loss: 0.8905 - val_accuracy: 0.6354 - val_loss: 0.8878\n",
            "Epoch 3/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452ms/step - accuracy: 0.7374 - loss: 0.7430"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 630ms/step - accuracy: 0.7369 - loss: 0.7430 - val_accuracy: 0.6771 - val_loss: 0.8708\n",
            "Epoch 4/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373ms/step - accuracy: 0.8153 - loss: 0.5365"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 509ms/step - accuracy: 0.8145 - loss: 0.5375 - val_accuracy: 0.7500 - val_loss: 0.7121\n",
            "Epoch 5/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476ms/step - accuracy: 0.7878 - loss: 0.5542"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 637ms/step - accuracy: 0.7887 - loss: 0.5540 - val_accuracy: 0.7604 - val_loss: 0.6906\n",
            "Epoch 6/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374ms/step - accuracy: 0.8222 - loss: 0.4888"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 508ms/step - accuracy: 0.8213 - loss: 0.4906 - val_accuracy: 0.7708 - val_loss: 0.6598\n",
            "Epoch 7/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480ms/step - accuracy: 0.7984 - loss: 0.5225"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 633ms/step - accuracy: 0.8001 - loss: 0.5220 - val_accuracy: 0.7812 - val_loss: 0.6776\n",
            "Epoch 8/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 483ms/step - accuracy: 0.8241 - loss: 0.4435 - val_accuracy: 0.7396 - val_loss: 0.7049\n",
            "Epoch 9/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472ms/step - accuracy: 0.8180 - loss: 0.4863"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 634ms/step - accuracy: 0.8156 - loss: 0.4870 - val_accuracy: 0.8021 - val_loss: 0.6225\n",
            "Epoch 10/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 485ms/step - accuracy: 0.8481 - loss: 0.4222 - val_accuracy: 0.7812 - val_loss: 0.6729\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7aed3413d2b0>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HY3Ei55s_EIc",
        "outputId": "f5a810b8-d859-46af-cf25-b9974c42eda3"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best_model.h5  dataset\tdrive  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tf2onnx\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 845
        },
        "id": "jljo7ALW_OkS",
        "outputId": "a6ba5fab-c86c-409d-8785-c2cb883d4eee"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tf2onnx\n",
            "  Downloading tf2onnx-1.16.1-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: numpy>=1.14.1 in /usr/local/lib/python3.12/dist-packages (from tf2onnx) (2.0.2)\n",
            "Collecting onnx>=1.4.1 (from tf2onnx)\n",
            "  Downloading onnx-1.20.1-cp312-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from tf2onnx) (2.32.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from tf2onnx) (1.17.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.12/dist-packages (from tf2onnx) (25.12.19)\n",
            "Collecting protobuf~=3.20 (from tf2onnx)\n",
            "  Downloading protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\n",
            "INFO: pip is looking at multiple versions of onnx to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting onnx>=1.4.1 (from tf2onnx)\n",
            "  Downloading onnx-1.20.0-cp312-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "  Downloading onnx-1.19.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (7.0 kB)\n",
            "  Downloading onnx-1.19.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (7.0 kB)\n",
            "  Downloading onnx-1.18.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "  Downloading onnx-1.17.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->tf2onnx) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->tf2onnx) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->tf2onnx) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->tf2onnx) (2026.1.4)\n",
            "Downloading tf2onnx-1.16.1-py3-none-any.whl (455 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m455.8/455.8 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx-1.17.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m94.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: protobuf, onnx, tf2onnx\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.5\n",
            "    Uninstalling protobuf-5.29.5:\n",
            "      Successfully uninstalled protobuf-5.29.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.20.3 which is incompatible.\n",
            "opentelemetry-proto 1.37.0 requires protobuf<7.0,>=5.0, but you have protobuf 3.20.3 which is incompatible.\n",
            "tensorflow-metadata 1.17.3 requires protobuf>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\n",
            "grain 0.2.15 requires protobuf>=5.28.3, but you have protobuf 3.20.3 which is incompatible.\n",
            "ydf 0.14.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed onnx-1.17.0 protobuf-3.20.3 tf2onnx-1.16.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "b35482e8a5e344a2993a12f211097cc5"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m tf2onnx.convert --keras best_model.h5 --output wafer_model.onnx\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frcT23HL_w-f",
        "outputId": "8d28bceb-db43-45ae-9d30-c9c96fdddcbc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2026-01-29 09:54:43.700271: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1769680483.720182   13693 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1769680483.726276   13693 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1769680483.742260   13693 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769680483.742285   13693 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769680483.742288   13693 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769680483.742292   13693 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-29 09:54:43.747002: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "<frozen runpy>:128: RuntimeWarning: 'tf2onnx.convert' found in sys.modules after import of package 'tf2onnx', but prior to execution of 'tf2onnx.convert'; this may result in unpredictable behaviour\n",
            "2026-01-29 09:54:54,640 - WARNING - ***IMPORTANT*** Installed protobuf is not cpp accelerated. Conversion will be extremely slow. See https://github.com/onnx/tensorflow-onnx/issues/1557\n",
            "2026-01-29 09:54:54.802339: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "I0000 00:00:1769680494.802494   13693 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "Traceback (most recent call last):\n",
            "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 88, in _run_code\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tf2onnx/convert.py\", line 714, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tf2onnx/convert.py\", line 248, in main\n",
            "    graph_def, inputs, outputs = tf_loader.from_keras(\n",
            "                                 ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tf2onnx/tf_loader.py\", line 668, in from_keras\n",
            "    _keras.backend.set_learning_phase(False)\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: module 'keras._tf_keras.keras.backend' has no attribute 'set_learning_phase'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"saved_model\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "Djsdh1ntAJP-",
        "outputId": "9dd08a9d-c714-405d-dd8d-5af54546c909"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3023181752.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"saved_model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model = load_model(\"best_model.h5\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Um7-mat5ASN4",
        "outputId": "f0502e82-1294-4e96-9557-dad84c720087"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m tf2onnx.convert --saved-model saved_model --output wafer_model.onnx\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9ZlYj2IAeQg",
        "outputId": "79238aa0-1586-4327-ee6e-54b21ac9c7a3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2026-01-29 09:57:49.059455: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1769680669.078628   14521 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1769680669.084474   14521 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1769680669.099139   14521 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769680669.099167   14521 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769680669.099171   14521 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769680669.099175   14521 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "<frozen runpy>:128: RuntimeWarning: 'tf2onnx.convert' found in sys.modules after import of package 'tf2onnx', but prior to execution of 'tf2onnx.convert'; this may result in unpredictable behaviour\n",
            "2026-01-29 09:57:59,494 - WARNING - ***IMPORTANT*** Installed protobuf is not cpp accelerated. Conversion will be extremely slow. See https://github.com/onnx/tensorflow-onnx/issues/1557\n",
            "2026-01-29 09:57:59.627867: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "I0000 00:00:1769680679.628036   14521 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13810 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "2026-01-29 09:57:59,632 - WARNING - '--tag' not specified for saved_model. Using --tag serve\n",
            "Traceback (most recent call last):\n",
            "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 88, in _run_code\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tf2onnx/convert.py\", line 714, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tf2onnx/convert.py\", line 242, in main\n",
            "    graph_def, inputs, outputs, initialized_tables, tensors_to_rename = tf_loader.from_saved_model(\n",
            "                                                                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tf2onnx/tf_loader.py\", line 636, in from_saved_model\n",
            "    _from_saved_model_v2(model_path, input_names, output_names,\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tf2onnx/tf_loader.py\", line 570, in _from_saved_model_v2\n",
            "    imported = tf.saved_model.load(model_path, tags=tag)  # pylint: disable=no-value-for-parameter\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tensorflow/python/saved_model/load.py\", line 912, in load\n",
            "    result = load_partial(export_dir, None, tags, options)[\"root\"]\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tensorflow/python/saved_model/load.py\", line 1016, in load_partial\n",
            "    loader_impl.parse_saved_model_with_debug_info(export_dir))\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tensorflow/python/saved_model/loader_impl.py\", line 59, in parse_saved_model_with_debug_info\n",
            "    saved_model = parse_saved_model(export_dir)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tensorflow/python/saved_model/loader_impl.py\", line 119, in parse_saved_model\n",
            "    raise IOError(\n",
            "OSError: SavedModel file does not exist at: saved_model/{saved_model.pbtxt|saved_model.pb}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ac9WLalSAu7Z",
        "outputId": "f36b48f6-353f-45ed-b113-3466c2465f9c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best_model.h5  dataset\tdrive  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model = load_model(\"best_model.h5\")\n",
        "\n",
        "model.export(\"saved_model\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPmxgLk2A1CK",
        "outputId": "89734243-ecc3-4ea0-e3e6-ffb7f7784f24"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved artifact at 'saved_model'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): List[TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='input_layer_5')]\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 4), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  136744054944592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136744054944016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136744054944208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136744054943632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136744054945168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136744054941328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136744054944784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136744054944976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136744054942096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136744054946128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136744054945552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136744054945744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136744054945936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136744054943440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136744054947088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136744054946512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136744054946704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136744054947280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136744054947664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136744054946320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136744054945360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136744054946896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910900944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136744054947472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136744054944400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910900560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910899984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910899792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910900176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910901904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910901328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910901520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910901712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910900752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910902864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910902288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910902480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910902672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910900368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910903824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910903248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910903440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910903632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910901136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910904784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910904208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910904400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910904592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910902096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910905744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910905168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910905360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910905552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910903056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910906704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910906128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910906320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910906512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910904016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910907664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910907088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910907280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910907472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910904976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910908624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910908048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910908240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910908432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910905936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910909584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910909008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910909200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910909392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910906896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910910544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910909968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910910160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910910352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910907856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910911504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910910928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910911120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910911312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910908816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910912464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910911888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910912080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910912272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910909776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910913424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910912848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910913040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910913232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910910736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910914384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910913808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910914000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910914192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910911696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910915344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910914768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910914960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910915536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910915920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910914576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910913616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910915152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911523344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910915728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910912656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911523536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911522576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911522384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911522960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911524496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911523920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911524112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911524304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911523728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911525456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911524880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911525072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911525264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911523152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911526416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911525840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911526032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911526224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911522768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911527376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911526800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911526992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911527184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911524688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911528336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911527760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911527952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911528144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911525648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911529296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911528720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911528912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911529104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911526608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911530256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911529680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911529872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911530064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911527568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911531216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911530640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911530832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911531024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911528528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911532176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911531600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911531792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911531984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911529488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911533136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911532560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911532752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911532944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911530448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911534096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911533520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911533712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911533904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911531408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911535056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911534480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911534672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911534864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911532368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911536016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911535440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911535632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911535824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911533328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911536976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911536400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911536592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911536784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911534288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911537936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911537360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911537552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911538128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911538512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911537168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911536208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911537744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910032016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911538320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911535248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910031440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910032400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910032208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910031632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910033552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910032976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910033168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910033360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910032592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910034512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910033936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910034128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910034320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910031824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910035472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910034896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910035088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910035280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910032784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910036432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910035856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910036048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910036240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910033744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910037392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910036816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910037008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910037200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910034704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910038352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910037776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910037968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910038160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910035664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910039312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910038736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910038928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910039120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910036624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910040272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910039696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910039888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910040080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910037584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910041232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910040656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910040848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910041040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910038544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910042192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910041616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910041808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910042000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910039504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910043152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910042576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910042768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910042960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910040464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910044112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910043536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910043728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910043920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910041424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910045072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910044496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910042384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910045840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910045264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ud3tD4LpA9cr",
        "outputId": "ceae0101-26f2-4bd3-a843-7c042e34276e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best_model.h5  dataset\tdrive  sample_data  saved_model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.export()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "fjLkjTGaBFUG",
        "outputId": "feb85f88-8061-412a-bac4-534f726e68e4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "Model.export() missing 1 required positional argument: 'filepath'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3743155256.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Model.export() missing 1 required positional argument: 'filepath'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.export(\"saved_model\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gfxr_XAkBNL0",
        "outputId": "657128a8-9496-4302-87f8-4d3566a6e2b5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved artifact at 'saved_model'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): List[TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='input_layer_5')]\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 4), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  136744054944592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136744054944016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136744054944208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136744054943632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136744054945168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136744054941328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136744054944784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136744054944976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136744054942096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136744054946128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136744054945552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136744054945744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136744054945936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136744054943440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136744054947088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136744054946512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136744054946704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136744054947280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136744054947664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136744054946320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136744054945360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136744054946896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910900944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136744054947472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136744054944400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910900560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910899984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910899792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910900176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910901904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910901328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910901520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910901712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910900752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910902864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910902288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910902480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910902672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910900368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910903824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910903248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910903440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910903632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910901136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910904784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910904208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910904400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910904592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910902096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910905744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910905168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910905360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910905552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910903056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910906704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910906128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910906320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910906512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910904016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910907664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910907088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910907280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910907472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910904976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910908624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910908048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910908240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910908432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910905936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910909584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910909008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910909200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910909392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910906896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910910544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910909968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910910160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910910352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910907856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910911504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910910928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910911120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910911312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910908816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910912464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910911888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910912080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910912272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910909776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910913424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910912848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910913040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910913232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910910736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910914384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910913808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910914000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910914192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910911696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910915344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910914768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910914960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910915536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910915920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910914576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910913616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910915152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911523344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910915728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910912656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911523536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911522576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911522384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911522960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911524496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911523920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911524112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911524304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911523728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911525456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911524880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911525072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911525264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911523152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911526416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911525840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911526032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911526224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911522768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911527376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911526800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911526992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911527184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911524688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911528336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911527760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911527952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911528144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911525648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911529296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911528720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911528912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911529104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911526608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911530256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911529680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911529872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911530064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911527568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911531216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911530640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911530832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911531024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911528528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911532176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911531600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911531792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911531984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911529488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911533136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911532560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911532752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911532944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911530448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911534096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911533520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911533712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911533904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911531408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911535056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911534480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911534672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911534864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911532368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911536016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911535440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911535632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911535824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911533328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911536976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911536400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911536592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911536784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911534288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911537936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911537360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911537552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911538128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911538512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911537168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911536208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911537744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910032016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911538320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743911535248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910031440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910032400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910032208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910031632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910033552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910032976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910033168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910033360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910032592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910034512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910033936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910034128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910034320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910031824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910035472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910034896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910035088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910035280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910032784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910036432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910035856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910036048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910036240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910033744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910037392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910036816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910037008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910037200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910034704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910038352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910037776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910037968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910038160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910035664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910039312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910038736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910038928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910039120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910036624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910040272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910039696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910039888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910040080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910037584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910041232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910040656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910040848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910041040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910038544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910042192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910041616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910041808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910042000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910039504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910043152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910042576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910042768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910042960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910040464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910044112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910043536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910043728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910043920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910041424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910045072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910044496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910042384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910045840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136743910045264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m tf2onnx.convert --saved-model saved_model --output wafer_model.onnx\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYsHHw5yBSvt",
        "outputId": "ab18c8f8-b414-4b3e-a573-9069fe255902"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2026-01-29 10:01:24.049195: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1769680884.071193   15440 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1769680884.081081   15440 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1769680884.103299   15440 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769680884.103329   15440 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769680884.103335   15440 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769680884.103338   15440 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "<frozen runpy>:128: RuntimeWarning: 'tf2onnx.convert' found in sys.modules after import of package 'tf2onnx', but prior to execution of 'tf2onnx.convert'; this may result in unpredictable behaviour\n",
            "2026-01-29 10:01:34,630 - WARNING - ***IMPORTANT*** Installed protobuf is not cpp accelerated. Conversion will be extremely slow. See https://github.com/onnx/tensorflow-onnx/issues/1557\n",
            "2026-01-29 10:01:34.818655: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "I0000 00:00:1769680894.818866   15440 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13810 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "2026-01-29 10:01:34,823 - WARNING - '--tag' not specified for saved_model. Using --tag serve\n",
            "2026-01-29 10:01:39,182 - INFO - Signatures found in model: [serve,serving_default].\n",
            "2026-01-29 10:01:39,182 - WARNING - '--signature_def' not specified, using first signature: serve\n",
            "2026-01-29 10:01:39,183 - INFO - Output names: ['output_0']\n",
            "I0000 00:00:1769680899.370642   15440 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1769680899.370852   15440 single_machine.cc:374] Starting new session\n",
            "I0000 00:00:1769680899.371812   15440 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13810 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "I0000 00:00:1769680901.529669   15440 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13810 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "I0000 00:00:1769680902.385016   15440 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
            "I0000 00:00:1769680902.385189   15440 single_machine.cc:374] Starting new session\n",
            "I0000 00:00:1769680902.386128   15440 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13810 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "2026-01-29 10:01:42,654 - INFO - Using tensorflow=2.19.0, onnx=1.17.0, tf2onnx=1.16.1/15c810\n",
            "2026-01-29 10:01:42,654 - INFO - Using opset <onnx, 15>\n",
            "2026-01-29 10:01:42,802 - INFO - Computed 0 values for constant folding\n",
            "2026-01-29 10:01:42,945 - ERROR - rewriter <function rewrite_constant_fold at 0x792ddc9cf600>: exception `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n",
            "Traceback (most recent call last):\n",
            "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 88, in _run_code\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tf2onnx/convert.py\", line 714, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tf2onnx/convert.py\", line 273, in main\n",
            "    model_proto, _ = _convert_common(\n",
            "                     ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tf2onnx/convert.py\", line 168, in _convert_common\n",
            "    g = process_tf_graph(tf_graph, const_node_values=const_node_values,\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tf2onnx/tfonnx.py\", line 464, in process_tf_graph\n",
            "    g = process_graphs(main_g, subgraphs, custom_op_handlers, inputs_as_nchw, outputs_as_nchw, continue_on_error,\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tf2onnx/tfonnx.py\", line 516, in process_graphs\n",
            "    g = process_parsed_graph(main_g, custom_op_handlers, inputs_as_nchw, outputs_as_nchw, continue_on_error,\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tf2onnx/tfonnx.py\", line 616, in process_parsed_graph\n",
            "    run_rewriters(g, rewriters, continue_on_error)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tf2onnx/tfonnx.py\", line 384, in run_rewriters\n",
            "    raise ex\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tf2onnx/tfonnx.py\", line 375, in run_rewriters\n",
            "    ops = func(g, g.get_nodes())\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tf2onnx/tfonnx.py\", line 77, in rewrite_constant_fold\n",
            "    \"Cast\": np.cast,\n",
            "            ^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/numpy/__init__.py\", line 397, in __getattr__\n",
            "    raise AttributeError(\n",
            "AttributeError: `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.26.4\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNMGHLXZBkJt",
        "outputId": "2bf433ae-00a5-494a-f2b3-a762f3ce8dc6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy==1.26.4 in /usr/local/lib/python3.12/dist-packages (1.26.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model = load_model(\"best_model.h5\")\n",
        "\n",
        "model.export(\"saved_model\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBus6SuQBuU6",
        "outputId": "34d98916-8f31-4d3f-cfba-0fd420d67b40"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved artifact at 'saved_model'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): List[TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='input_layer_5')]\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 4), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  136690468724496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690468725072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690468726800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690468726416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690468725264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690468726992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690468725456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690468725840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690468725648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690468726224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690468727760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690468728144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690468727568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690468728336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690468728528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690468727184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690468730064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690468730256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690468729488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690468728912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690468726032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690468729104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690468729296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690468729680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690468731216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690468730640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690468730832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690468731024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690468728720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690468732176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690468731600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690468731792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690468732368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690468732752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690468731408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690468732560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690468723536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690468731984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690468724304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690468730448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690468723920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460722000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460722384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460721424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460722960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460721616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460721232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460722768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460721808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460723920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460723344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460723536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460723728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460722576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460724880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460724304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460724496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460724688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460722192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460725840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460725264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460725456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460725648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460723152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460726800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460726224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460726416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460726608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460724112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460727760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460727184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460727376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460727568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460725072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460728720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460728144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460728336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460728528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460726032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460729680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460729104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460729296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460729488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460726992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460730640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460730064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460730256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460730448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460727952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460731600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460731024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460731216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460731408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460728912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460732560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460731984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460732176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460732368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460729872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460733520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460732944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460733136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460733328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460730832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460734480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460733904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460734096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460734288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460731792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460735440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460734864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460735056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460735248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460732752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460736400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460735824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460736016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460736784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460733712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460737360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460736208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460736976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460734672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460737168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460736592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690460735632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290442704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290442896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290442320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290444048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290442512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290443664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290443856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290443280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290445008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290444432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290444624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290444816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290443472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290445968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290445392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290445584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290445776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290443088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290446928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290446352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290446544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290446736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290444240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290447888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290447312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290447504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290447696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290445200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290448848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290448272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290448464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290448656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290446160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290449808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290449232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290449424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290449616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290447120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290450768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290450192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290450384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290450576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290448080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290451728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290451152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290451344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290451536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290449040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290452688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290452112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290452304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290452496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290450000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290453648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290453072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290453264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290453456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290450960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290454608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290454032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290454224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290454416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290451920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290455568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290454992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290455184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290455376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290452880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290456528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290455952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290456144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290456336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290453840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290457488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290456912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290457104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290457872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290454800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290458448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290457296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290458064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290455760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290458256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290457680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690290456720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690291115600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690291115792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690291115024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690291114448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690291114256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690291115408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690291115216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690291114832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690291116752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690291116176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690291116368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690291116560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690291114064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690291117712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690291117136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690291117328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690291117520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690291114640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690291118672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690291118096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690291118288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690291118480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690291115984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690291119632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690291119056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690291119248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690291119440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690291116944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690291120592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690291120016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690291120208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690291120400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690291117904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690291121552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690291120976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690291121168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690291121360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690291118864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690291122512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690291121936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690291122128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690291122320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690291119824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690291123472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690291122896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690291123088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690291123280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690291120784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690291124432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690291123856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690291121744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690291125200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136690291124624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m tf2onnx.convert --saved-model saved_model --output wafer_model.onnx\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhVLIvEhB3aU",
        "outputId": "e6372a27-bd30-44fd-96e6-8941d566cc71"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2026-01-29 10:03:56.530555: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1769681036.549768   16273 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1769681036.555939   16273 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1769681036.576864   16273 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769681036.576896   16273 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769681036.576916   16273 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769681036.576920   16273 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "<frozen runpy>:128: RuntimeWarning: 'tf2onnx.convert' found in sys.modules after import of package 'tf2onnx', but prior to execution of 'tf2onnx.convert'; this may result in unpredictable behaviour\n",
            "2026-01-29 10:04:07,503 - WARNING - ***IMPORTANT*** Installed protobuf is not cpp accelerated. Conversion will be extremely slow. See https://github.com/onnx/tensorflow-onnx/issues/1557\n",
            "2026-01-29 10:04:07.638756: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "I0000 00:00:1769681047.638956   16273 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13810 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "2026-01-29 10:04:07,643 - WARNING - '--tag' not specified for saved_model. Using --tag serve\n",
            "2026-01-29 10:04:12,056 - INFO - Signatures found in model: [serve,serving_default].\n",
            "2026-01-29 10:04:12,056 - WARNING - '--signature_def' not specified, using first signature: serve\n",
            "2026-01-29 10:04:12,057 - INFO - Output names: ['output_0']\n",
            "I0000 00:00:1769681052.247682   16273 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1769681052.247878   16273 single_machine.cc:374] Starting new session\n",
            "I0000 00:00:1769681052.248769   16273 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13810 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "I0000 00:00:1769681055.377163   16273 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13810 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "I0000 00:00:1769681056.344479   16273 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
            "I0000 00:00:1769681056.344642   16273 single_machine.cc:374] Starting new session\n",
            "I0000 00:00:1769681056.345592   16273 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13810 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "2026-01-29 10:04:16,595 - INFO - Using tensorflow=2.19.0, onnx=1.17.0, tf2onnx=1.16.1/15c810\n",
            "2026-01-29 10:04:16,595 - INFO - Using opset <onnx, 15>\n",
            "2026-01-29 10:04:16,759 - INFO - Computed 0 values for constant folding\n",
            "2026-01-29 10:04:17,059 - INFO - Optimizing ONNX model\n",
            "2026-01-29 10:04:18,719 - INFO - After optimization: Add -35 (64->29), Const -92 (221->129), GlobalAveragePool +1 (0->1), Identity -2 (2->0), ReduceMean -1 (1->0), Reshape -17 (17->0), Squeeze +1 (0->1), Transpose -120 (121->1)\n",
            "2026-01-29 10:04:18,753 - INFO - \n",
            "2026-01-29 10:04:18,753 - INFO - Successfully converted TensorFlow model saved_model to ONNX\n",
            "2026-01-29 10:04:18,753 - INFO - Model inputs: ['input_layer_5']\n",
            "2026-01-29 10:04:18,753 - INFO - Model outputs: ['output_0']\n",
            "2026-01-29 10:04:18,753 - INFO - ONNX model is saved at wafer_model.onnx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIlJVWHzCBaV",
        "outputId": "974ab490-3d65-4b72-c71d-c881d3c02f2b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best_model.h5  dataset\tdrive  sample_data  saved_model  wafer_model.onnx\n"
          ]
        }
      ]
    }
  ]
}